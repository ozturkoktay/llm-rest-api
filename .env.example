# API Configuration
API_TITLE="LLM API"
API_VERSION="1.0.0"
API_HOST="0.0.0.0"
API_PORT=8000

# Model Configuration
MODEL_TYPE="ollama"
MODEL_NAME="llama2"

# Ollama Configuration
OLLAMA_BASE_URL="http://localhost:11434"

# Performance
MAX_CONCURRENT_REQUESTS=10
REQUEST_TIMEOUT=300

# CORS
CORS_ENABLED=true
CORS_ORIGINS=["*"]

# Logging
LOG_LEVEL="INFO"
